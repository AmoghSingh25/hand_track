{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf0d4e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SGD' from 'keras.optimizers' (d:\\programs\\python\\lib\\site-packages\\keras\\optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b3d68ac860e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SGD' from 'keras.optimizers' (d:\\programs\\python\\lib\\site-packages\\keras\\optimizers.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17211da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('saved_model/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c6306cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105600\n",
      "Found 105600 files belonging to 44 classes.\n",
      "Using 84480 files for training.\n",
      "Found 105600 files belonging to 44 classes.\n",
      "Using 104544 files for validation.\n",
      "['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"Image/0/1.jpg\")\n",
    "h,w,c=img.shape\n",
    "del img\n",
    "data_dir=pathlib.Path(\"Image\")\n",
    "data_di1r=pathlib.Path(\"validate\")\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "batch_size = 32\n",
    "img_height = h\n",
    "img_width = w\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.99,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1f15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105600\n",
      "Found 51 files belonging to 2 classes.\n",
      "Using 41 files for training.\n",
      "Found 105600 files belonging to 44 classes.\n",
      "Using 21120 files for validation.\n",
      "['11', '24']\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"Image/0/1.jpg\")\n",
    "h,w,c=img.shape\n",
    "del img\n",
    "data_dir=pathlib.Path(\"Image\")\n",
    "data_dir1=pathlib.Path(\"validate\")\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "batch_size = 32\n",
    "img_height = h\n",
    "img_width = w\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir1,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9196329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 48.1753 - accuracy: 0.0000e+00 - val_loss: 17.6757 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12.1788 - accuracy: 0.1463 - val_loss: 3.8747 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3327 - accuracy: 0.5610 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3293e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 2.0585e-04 - accuracy: 1.0000 - val_loss: 6.5420e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.5511e-05 - accuracy: 1.0000 - val_loss: 2.8467e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.1418e-05 - accuracy: 1.0000 - val_loss: 8.5115e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9.1151e-06 - accuracy: 1.0000 - val_loss: 2.8133e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.4976e-06 - accuracy: 1.0000 - val_loss: 1.4782e-06 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69435b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 196s - loss: 12.1134 - accuracy: 0.1264\n",
      "Test model, accuracy: 12.64%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_ds, verbose=2)\n",
    "print(\"Test model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1c2adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to 11 with a 99.97 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "temp=cv2.imread('test.png')\n",
    "\n",
    "h,w,c=temp.shape\n",
    "img_height = h\n",
    "img_width = w\n",
    "temp = cv2.resize(temp, (50, 50),\n",
    "               interpolation = cv2.INTER_AREA)\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    \"test.png\", target_size=(img_height, img_width)\n",
    ")\n",
    "img=temp\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6c29c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/model3\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf2414be",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89604743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0467e-07 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00001: saving model to training_1\\cp.ckpt\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00002: saving model to training_1\\cp.ckpt\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: saving model to training_1\\cp.ckpt\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: saving model to training_1\\cp.ckpt\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: saving model to training_1\\cp.ckpt\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00006: saving model to training_1\\cp.ckpt\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: saving model to training_1\\cp.ckpt\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00008: saving model to training_1\\cp.ckpt\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00009: saving model to training_1\\cp.ckpt\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.2336e-08 - accuracy: 1.0000 - val_loss: 7.1526e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00010: saving model to training_1\\cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
