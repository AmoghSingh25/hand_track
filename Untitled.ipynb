{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf0d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from cnn_tf import cnn_model_fn\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "#from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350e8f0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'model_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6edc59b9731a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"saved_model/cnn_model3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cnn_model_keras2.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprocessed_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_process_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_input_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprocessed_array\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'model_fn'"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(model_dir=\"saved_model/cnn_model3\")\n",
    "prediction = None\n",
    "model = keras.models.load_model('cnn_model_keras2.h5')\n",
    "processed_array = tf_process_image(image)\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\":processed_array}, shuffle=False)\n",
    "pred = classifier.predict(input_fn=pred_input_fn)\n",
    "prediction = next(pred)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17211da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('saved_model\\work_model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c6306cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62400\n",
      "Found 62400 files belonging to 26 classes.\n",
      "Using 49920 files for training.\n",
      "Found 62400 files belonging to 26 classes.\n",
      "Using 61776 files for validation.\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"img/Letters/A/1.jpg\")\n",
    "h,w,c=img.shape\n",
    "del img\n",
    "data_dir=pathlib.Path(\"img/Letters\")\n",
    "data_di1r=pathlib.Path(\"validate\")\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "batch_size = 32\n",
    "img_height = h\n",
    "img_width = w\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.99,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1f15c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fde8d4fd217d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image/0/1.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*/*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"Image/0/1.jpg\")\n",
    "h,w,c=img.shape\n",
    "del img\n",
    "data_dir=pathlib.Path(\"Image\")\n",
    "image_count = len(list(data_dir.glowb('*/*.jpg')))\n",
    "print(image_count)\n",
    "batch_size = 32\n",
    "img_height = h\n",
    "img_width = w\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa8bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(class_names)\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(50,50, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72492023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9196329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000294849221F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000294849221F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1556/1560 [============================>.] - ETA: 1s - loss: 0.0701 - accuracy: 0.9801WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000294854773A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000294854773A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1560/1560 [==============================] - 501s 320ms/step - loss: 0.0699 - accuracy: 0.9801 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 2/10\n",
      "1560/1560 [==============================] - 31s 20ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 8.8142e-04 - val_accuracy: 0.9997\n",
      "Epoch 3/10\n",
      "1560/1560 [==============================] - 31s 20ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 1.6366e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1560/1560 [==============================] - 30s 19ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "1560/1560 [==============================] - 29s 19ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.3170e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1560/1560 [==============================] - 32s 21ms/step - loss: 4.4114e-06 - accuracy: 1.0000 - val_loss: 2.0619e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1560/1560 [==============================] - 30s 19ms/step - loss: 1.0690e-06 - accuracy: 1.0000 - val_loss: 7.9918e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1560/1560 [==============================] - 27s 18ms/step - loss: 4.2801e-07 - accuracy: 1.0000 - val_loss: 4.0594e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1560/1560 [==============================] - 27s 18ms/step - loss: 1.9239e-07 - accuracy: 1.0000 - val_loss: 2.0618e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1560/1560 [==============================] - 27s 17ms/step - loss: 8.5045e-08 - accuracy: 1.0000 - val_loss: 1.0781e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e69435b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1931/1931 - 13s - loss: 1.0781e-07 - accuracy: 1.0000\n",
      "Test model, accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_ds, verbose=2)\n",
    "print(\"Test model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c2adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029540CE7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000029540CE7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "This image most likely belongs to A with a 100.00 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "img_l='2.jpg'\n",
    "temp=cv2.imread(img_l)\n",
    "\n",
    "h,w,c=temp.shape\n",
    "img_height = h\n",
    "img_width = w\n",
    "temp = cv2.resize(temp, (50, 50),\n",
    "               interpolation = cv2.INTER_AREA)\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    img_l, target_size=(img_height, img_width)\n",
    ")\n",
    "img=temp\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6c29c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000295579259D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000295579259D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('signature_function', 'signature_key'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: saved_model/letters_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/letters_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf2414be",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_letters/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89604743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "540/540 [==============================] - 9s 16ms/step - loss: 2.5405e-07 - accuracy: 1.0000 - val_loss: 2.8032e-07 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00001: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 2/10\n",
      "540/540 [==============================] - 9s 17ms/step - loss: 1.8514e-07 - accuracy: 1.0000 - val_loss: 2.0801e-07 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00002: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 3/10\n",
      "540/540 [==============================] - 9s 16ms/step - loss: 1.3732e-07 - accuracy: 1.0000 - val_loss: 1.5639e-07 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 4/10\n",
      "540/540 [==============================] - 9s 17ms/step - loss: 1.0294e-07 - accuracy: 1.0000 - val_loss: 1.2182e-07 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 5/10\n",
      "540/540 [==============================] - 9s 16ms/step - loss: 7.5478e-08 - accuracy: 1.0000 - val_loss: 9.0945e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 6/10\n",
      "540/540 [==============================] - 9s 17ms/step - loss: 5.7335e-08 - accuracy: 1.0000 - val_loss: 7.1785e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00006: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 7/10\n",
      "540/540 [==============================] - 9s 17ms/step - loss: 4.3731e-08 - accuracy: 1.0000 - val_loss: 5.3860e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 8/10\n",
      "540/540 [==============================] - 10s 18ms/step - loss: 3.2355e-08 - accuracy: 1.0000 - val_loss: 4.2889e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00008: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 9/10\n",
      "540/540 [==============================] - 9s 16ms/step - loss: 2.4821e-08 - accuracy: 1.0000 - val_loss: 3.2733e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00009: saving model to training_numbers\\cp.ckpt\n",
      "Epoch 10/10\n",
      "540/540 [==============================] - 9s 17ms/step - loss: 1.8633e-08 - accuracy: 1.0000 - val_loss: 2.5096e-08 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00010: saving model to training_numbers\\cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
